#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EPUBè§£æè„šæœ¬ - æå–ç¬¬ä¸€ç« å†…å®¹å¹¶ç”ŸæˆJSONæ–‡ä»¶
æŒ‰ç…§Clickæ•°æ®å¥‘çº¦è§„èŒƒç”Ÿæˆç« èŠ‚JSONæ•°æ®
"""

import json
import os
import re
import uuid
from pathlib import Path
from typing import List, Dict, Any

try:
    import ebooklib
    from ebooklib import epub
except ImportError:
    print("è¯·å®‰è£…ebooklibåº“: pip install EbookLib")
    exit(1)

from bs4 import BeautifulSoup

class EPUBParser:
    def __init__(self, epub_path: str):
        self.epub_path = epub_path
        self.book = None
        self.book_id = str(uuid.uuid4())[:8]  # ç”Ÿæˆç®€çŸ­çš„book_id
        
    def load_epub(self) -> bool:
        """åŠ è½½EPUBæ–‡ä»¶"""
        try:
            print(f"ğŸ“š æ­£åœ¨åŠ è½½EPUBæ–‡ä»¶: {self.epub_path}")
            self.book = epub.read_epub(self.epub_path)
            print(f"âœ… EPUBæ–‡ä»¶åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ EPUBæ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return False
    
    def get_book_metadata(self) -> Dict[str, Any]:
        """è·å–ä¹¦ç±å…ƒæ•°æ®"""
        metadata = {
            'title': 'Unknown',
            'author': 'Unknown',
            'language': 'zh'
        }
        
        if self.book:
            # è·å–æ ‡é¢˜
            title = self.book.get_metadata('DC', 'title')
            if title:
                metadata['title'] = title[0][0]
                
            # è·å–ä½œè€…
            creator = self.book.get_metadata('DC', 'creator')
            if creator:
                metadata['author'] = creator[0][0]
                
            # è·å–è¯­è¨€
            language = self.book.get_metadata('DC', 'language')
            if language:
                metadata['language'] = language[0][0]
                
        print(f"ğŸ“– ä¹¦ç±ä¿¡æ¯:")
        print(f"   æ ‡é¢˜: {metadata['title']}")
        print(f"   ä½œè€…: {metadata['author']}")
        print(f"   è¯­è¨€: {metadata['language']}")
        
        return metadata
    
    def extract_text_from_html(self, html_content: str) -> str:
        """ä»HTMLå†…å®¹ä¸­æå–çº¯æ–‡æœ¬"""
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ç§»é™¤scriptå’Œstyleæ ‡ç­¾
        for script in soup(["script", "style"]):
            script.decompose()
            
        # è·å–æ–‡æœ¬å¹¶æ¸…ç†
        text = soup.get_text()
        
        # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        
        return text
    
    def split_into_paragraphs(self, text: str) -> List[Dict[str, Any]]:
        """å°†æ–‡æœ¬åˆ†å‰²ä¸ºæ®µè½"""
        # æŒ‰æ¢è¡Œç¬¦åˆ†å‰²æ®µè½
        raw_paragraphs = text.split('\n')
        paragraphs = []
        char_offset = 0
        
        for i, para_text in enumerate(raw_paragraphs):
            para_text = para_text.strip()
            if para_text:  # è·³è¿‡ç©ºæ®µè½
                paragraph = {
                    'paragraph_index': len(paragraphs),
                    'text': para_text,
                    'char_start': char_offset,
                    'char_end': char_offset + len(para_text)
                }
                paragraphs.append(paragraph)
                char_offset += len(para_text) + 1  # +1 for the newline character
                
        print(f"ğŸ“ æ®µè½åˆ†æ:")
        print(f"   æ€»æ®µè½æ•°: {len(paragraphs)}")
        if paragraphs:
            print(f"   ç¬¬ä¸€æ®µé¢„è§ˆ: {paragraphs[0]['text'][:50]}...")
            if len(paragraphs) > 1:
                print(f"   æœ€åä¸€æ®µé¢„è§ˆ: {paragraphs[-1]['text'][:50]}...")
            
        return paragraphs
    
    def find_first_chapter(self) -> tuple:
        """æŸ¥æ‰¾ç¬¬ä¸€ç« å†…å®¹"""
        print(f"ğŸ” æ­£åœ¨æŸ¥æ‰¾ç¬¬ä¸€ç« å†…å®¹...")
        
        # è·å–æ‰€æœ‰æ–‡æ¡£é¡¹ç›®
        items = list(self.book.get_items_of_type(ebooklib.ITEM_DOCUMENT))
        print(f"ğŸ“„ æ‰¾åˆ° {len(items)} ä¸ªæ–‡æ¡£é¡¹ç›®")
        
        chapter_patterns = [
            r'ç¬¬ä¸€ç« |ç¬¬1ç« |chapter\s*1|chapter\s*one',
            r'chapter\s*i(?!\w)',  # Roman numeral I
            r'1\.|1\s',  # Numbered chapters
        ]
        
        for i, item in enumerate(items):
            try:
                content = item.get_content().decode('utf-8')
                text = self.extract_text_from_html(content)
                
                print(f"ğŸ“‹ æ£€æŸ¥æ–‡æ¡£ {i+1}: {item.get_name()}")
                print(f"   å†…å®¹é•¿åº¦: {len(text)} å­—ç¬¦")
                if len(text) > 100:
                    print(f"   å‰100å­—ç¬¦: {text[:100]}...")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ç« èŠ‚æ ‡è¯†
                for pattern in chapter_patterns:
                    if re.search(pattern, text, re.IGNORECASE):
                        print(f"âœ… æ‰¾åˆ°ç¬¬ä¸€ç« ! åŒ¹é…æ¨¡å¼: {pattern}")
                        return text, item.get_name()
                
                # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„ç« èŠ‚æ ‡è¯†ï¼Œæ£€æŸ¥å†…å®¹é•¿åº¦
                # é€šå¸¸ç¬¬ä¸€ç« ä¼šæœ‰ç›¸å½“çš„å†…å®¹é•¿åº¦
                if len(text.strip()) > 500:  # è‡³å°‘500å­—ç¬¦
                    print(f"ğŸ“– æ ¹æ®å†…å®¹é•¿åº¦åˆ¤æ–­ä¸ºç¬¬ä¸€ç« å€™é€‰")
                    return text, item.get_name()
                    
            except Exception as e:
                print(f"âš ï¸ å¤„ç†æ–‡æ¡£ {item.get_name()} æ—¶å‡ºé”™: {e}")
                continue
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„ç¬¬ä¸€ç« ï¼Œè¿”å›ç¬¬ä¸€ä¸ªæœ‰å†…å®¹çš„æ–‡æ¡£
        for item in items:
            try:
                content = item.get_content().decode('utf-8')
                text = self.extract_text_from_html(content)
                if len(text.strip()) > 100:
                    print(f"ğŸ“– ä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ–‡æ¡£ä½œä¸ºç¬¬ä¸€ç« : {item.get_name()}")
                    return text, item.get_name()
            except:
                continue
                
        raise Exception("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç¬¬ä¸€ç« å†…å®¹")
    
    def preview_chapter(self) -> Dict[str, Any]:
        """é¢„è§ˆç¬¬ä¸€ç« è§£æç»“æœï¼Œä¸ç”Ÿæˆæ–‡ä»¶"""
        if not self.load_epub():
            return None
            
        # è·å–ä¹¦ç±å…ƒæ•°æ®
        metadata = self.get_book_metadata()
        
        # æŸ¥æ‰¾ç¬¬ä¸€ç« 
        chapter_text, chapter_source = self.find_first_chapter()
        
        # åˆ†å‰²æ®µè½
        paragraphs = self.split_into_paragraphs(chapter_text)
        
        # æ„å»ºæ•°æ®ç»“æ„
        chapter_data = {
            "book_id": self.book_id,
            "metadata": metadata,
            "chapter_info": {
                "chapter_index": 1,
                "title": "ç¬¬ä¸€ç« ",
                "word_count": len(chapter_text),
                "source_file": chapter_source,
                "paragraph_count": len(paragraphs)
            }
        }
        
        print(f"\nğŸ“‹ è§£æé¢„è§ˆç»“æœ:")
        print(f"ğŸ“– ä¹¦ç±ä¿¡æ¯: {metadata['title']} - {metadata['author']}")
        print(f"ğŸ†” ä¹¦ç±ID: {self.book_id}")
        print(f"ğŸ“„ æºæ–‡ä»¶: {chapter_source}")
        print(f"ğŸ“Š ç¬¬ä¸€ç« ç»Ÿè®¡:")
        print(f"   å­—ç¬¦æ€»æ•°: {len(chapter_text)}")
        print(f"   æ®µè½æ€»æ•°: {len(paragraphs)}")
        
        # æ˜¾ç¤ºå‰3ä¸ªæ®µè½çš„é¢„è§ˆ
        print(f"\nğŸ“ æ®µè½é¢„è§ˆ:")
        for i, para in enumerate(paragraphs[:3]):
            print(f"   æ®µè½{i+1}: {para['text'][:80]}...")
            print(f"           ä½ç½®: {para['char_start']}-{para['char_end']}")
        
        if len(paragraphs) > 3:
            print(f"   ... è¿˜æœ‰ {len(paragraphs)-3} ä¸ªæ®µè½")
            
        return chapter_data
    
    def generate_chapter_json(self, output_dir: str = "output") -> str:
        """ç”Ÿæˆç¬¬ä¸€ç« çš„JSONæ–‡ä»¶"""
        if not self.load_epub():
            return None
            
        # è·å–ä¹¦ç±å…ƒæ•°æ®
        metadata = self.get_book_metadata()
        
        # æŸ¥æ‰¾ç¬¬ä¸€ç« 
        chapter_text, chapter_source = self.find_first_chapter()
        
        # åˆ†å‰²æ®µè½
        paragraphs = self.split_into_paragraphs(chapter_text)
        
        # æ„å»ºJSONæ•°æ®ç»“æ„
        chapter_data = {
            "book_id": self.book_id,
            "metadata": metadata,
            "chapters": [
                {
                    "chapter_index": 1,
                    "title": "ç¬¬ä¸€ç« ",
                    "content": chapter_text,
                    "word_count": len(chapter_text),
                    "source_file": chapter_source,
                    "paragraphs": paragraphs
                }
            ]
        }
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        safe_title = re.sub(r'[^\w\s-]', '', metadata['title']).strip()
        safe_title = re.sub(r'[-\s]+', '-', safe_title)
        output_file = os.path.join(output_dir, f"{safe_title}_chapter1.json")
        
        # å†™å…¥JSONæ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(chapter_data, f, ensure_ascii=False, indent=2)
            
        print(f"\nâœ… JSONæ–‡ä»¶ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   å­—ç¬¦æ€»æ•°: {len(chapter_text)}")
        print(f"   æ®µè½æ€»æ•°: {len(paragraphs)}")
        print(f"   ä¹¦ç±ID: {self.book_id}")
        print(f"   æ–‡ä»¶å¤§å°: {os.path.getsize(output_file)} å­—èŠ‚")
        
        return output_file

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ŒåŸºäºå½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    epub_dir = os.path.join(script_dir, "epub-files")
    output_dir = os.path.join(script_dir, "output")
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    preview_mode = len(sys.argv) > 1 and sys.argv[1] == "--preview"
    
    # è·å–epubæ–‡ä»¶åˆ—è¡¨
    epub_files = [f for f in os.listdir(epub_dir) if f.endswith('.epub')]
    
    if preview_mode:
        print(f"ğŸ‘€ é¢„è§ˆæ¨¡å¼ - åªæ˜¾ç¤ºè§£æç»“æœï¼Œä¸ç”Ÿæˆæ–‡ä»¶")
    else:
        print(f"ğŸš€ å¼€å§‹å¤„ç†EPUBæ–‡ä»¶...")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    
    print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {epub_dir}")
    print(f"ğŸ“š æ‰¾åˆ° {len(epub_files)} ä¸ªEPUBæ–‡ä»¶\n")
    
    for epub_file in epub_files:
        epub_path = os.path.join(epub_dir, epub_file)
        print(f"{'='*60}")
        print(f"ğŸ”„ å¤„ç†æ–‡ä»¶: {epub_file}")
        print(f"{'='*60}")
        
        try:
            parser = EPUBParser(epub_path)
            
            if preview_mode:
                result = parser.preview_chapter()
                if result:
                    print(f"âœ… {epub_file} é¢„è§ˆå®Œæˆ\n")
                else:
                    print(f"âŒ {epub_file} é¢„è§ˆå¤±è´¥\n")
            else:
                output_file = parser.generate_chapter_json(output_dir)
                if output_file:
                    print(f"âœ… {epub_file} å¤„ç†å®Œæˆ\n")
                else:
                    print(f"âŒ {epub_file} å¤„ç†å¤±è´¥\n")
                    
        except Exception as e:
            print(f"âŒ å¤„ç† {epub_file} æ—¶å‘ç”Ÿé”™è¯¯: {e}\n")
    
    if preview_mode:
        print(f"ğŸ‘€ é¢„è§ˆå®Œæˆ! ä½¿ç”¨ 'python epub_parser.py' ç”ŸæˆJSONæ–‡ä»¶")
    else:
        print(f"ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ!")

if __name__ == "__main__":
    main()