#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EPUBç»“æ„åˆ†æå™¨ - è¯¦ç»†åˆ†æEPUBæ–‡ä»¶çš„å®Œæ•´ç»“æ„
ç”¨äºç†è§£EPUBçš„ç»„ç»‡æ–¹å¼ï¼Œæ‰¾åˆ°æ­£ç¡®çš„ç« èŠ‚è¯†åˆ«æ–¹æ³•
"""

import json
import os
from pathlib import Path
from typing import List, Dict, Any

try:
    import ebooklib
    from ebooklib import epub
except ImportError:
    print("è¯·å®‰è£…ebooklibåº“: pip install EbookLib")
    exit(1)

from bs4 import BeautifulSoup

class EPUBStructureAnalyzer:
    def __init__(self, epub_path: str):
        self.epub_path = epub_path
        self.book = None
        
    def get_item_type_name(self, item_type):
        """è·å–é¡¹ç›®ç±»å‹çš„å¯è¯»åç§°"""
        type_map = {
            ebooklib.ITEM_UNKNOWN: 'UNKNOWN',
            ebooklib.ITEM_IMAGE: 'IMAGE', 
            ebooklib.ITEM_STYLE: 'STYLE',
            ebooklib.ITEM_SCRIPT: 'SCRIPT',
            ebooklib.ITEM_NAVIGATION: 'NAVIGATION',
            ebooklib.ITEM_VECTOR: 'VECTOR',
            ebooklib.ITEM_FONT: 'FONT',
            ebooklib.ITEM_VIDEO: 'VIDEO',
            ebooklib.ITEM_AUDIO: 'AUDIO',
            ebooklib.ITEM_DOCUMENT: 'DOCUMENT',
            ebooklib.ITEM_COVER: 'COVER'
        }
        return type_map.get(item_type, f'TYPE_{item_type}')
        
    def load_epub(self) -> bool:
        """åŠ è½½EPUBæ–‡ä»¶"""
        try:
            print(f"ğŸ“š æ­£åœ¨åŠ è½½EPUBæ–‡ä»¶: {self.epub_path}")
            self.book = epub.read_epub(self.epub_path)
            print(f"âœ… EPUBæ–‡ä»¶åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ EPUBæ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return False
    
    def analyze_metadata(self) -> Dict[str, Any]:
        """åˆ†æä¹¦ç±å…ƒæ•°æ®"""
        print("\n" + "="*60)
        print("ğŸ“– ä¹¦ç±å…ƒæ•°æ®åˆ†æ")
        print("="*60)
        
        metadata = {}
        
        if self.book:
            # è·å–æ‰€æœ‰å…ƒæ•°æ®
            for namespace, items in self.book.metadata.items():
                print(f"\nğŸ“‹ å‘½åç©ºé—´: {namespace}")
                metadata[namespace] = []
                
                for item in items:
                    try:
                        if isinstance(item, (list, tuple)) and len(item) >= 1:
                            item_data = {
                                'value': item[0],
                                'attributes': dict(item[1]) if len(item) > 1 and item[1] else {}
                            }
                            metadata[namespace].append(item_data)
                            attrs_str = dict(item[1]) if len(item) > 1 and item[1] else ''
                            print(f"   - {item[0]} {attrs_str}")
                        else:
                            # å¤„ç†å…¶ä»–æ ¼å¼çš„å…ƒæ•°æ®
                            item_data = {
                                'value': str(item),
                                'attributes': {}
                            }
                            metadata[namespace].append(item_data)
                            print(f"   - {item}")
                    except Exception as e:
                        print(f"   âš ï¸ å¤„ç†å…ƒæ•°æ®é¡¹æ—¶å‡ºé”™: {e}, é¡¹ç›®: {item}")
                        continue
        
        return metadata
    
    def analyze_spine(self) -> List[Dict[str, Any]]:
        """åˆ†æä¹¦ç±è„ŠæŸ±ï¼ˆé˜…è¯»é¡ºåºï¼‰"""
        print("\n" + "="*60)
        print("ğŸ“š ä¹¦ç±è„ŠæŸ±åˆ†æï¼ˆé˜…è¯»é¡ºåºï¼‰")
        print("="*60)
        
        spine_info = []
        
        if self.book and self.book.spine:
            print(f"\nğŸ“„ è„ŠæŸ±åŒ…å« {len(self.book.spine)} ä¸ªé¡¹ç›®:")
            
            for i, (item_id, linear) in enumerate(self.book.spine):
                try:
                    # æŸ¥æ‰¾å¯¹åº”çš„é¡¹ç›®
                    item = None
                    for book_item in self.book.get_items():
                        if book_item.get_id() == item_id:
                            item = book_item
                            break
                    
                    spine_item = {
                        'index': i,
                        'id': item_id,
                        'linear': linear,
                        'file_name': item.get_name() if item else 'Unknown',
                        'media_type': item.get_type() if item else 'Unknown'
                    }
                    spine_info.append(spine_item)
                    
                    print(f"   {i+1:2d}. ID: {item_id:20s} Linear: {linear:5s} File: {spine_item['file_name']}")
                except Exception as e:
                    print(f"   {i+1:2d}. âŒ å¤„ç†è„ŠæŸ±é¡¹ç›® {item_id if 'item_id' in locals() else 'Unknown'} æ—¶å‡ºé”™: {e}")
                    continue
        
        return spine_info
    
    def analyze_toc(self) -> List[Dict[str, Any]]:
        """åˆ†æç›®å½•ç»“æ„"""
        print("\n" + "="*60)
        print("ğŸ“‘ ç›®å½•ç»“æ„åˆ†æ")
        print("="*60)
        
        toc_info = []
        
        if self.book and self.book.toc:
            print(f"\nğŸ“‹ ç›®å½•åŒ…å« {len(self.book.toc)} ä¸ªé¡¹ç›®:")
            
            def process_toc_item(item, level=0):
                indent = "  " * level
                
                try:
                    if isinstance(item, tuple):
                        # è¿™æ˜¯ä¸€ä¸ªç« èŠ‚é¡¹ç›®
                        section, children = item
                        if hasattr(section, 'title') and hasattr(section, 'href'):
                            toc_item = {
                                'level': level,
                                'title': section.title,
                                'href': section.href,
                                'type': 'section'
                            }
                            toc_info.append(toc_item)
                            print(f"{indent}ğŸ“– {section.title} -> {section.href}")
                            
                            # å¤„ç†å­é¡¹ç›®
                            for child in children:
                                process_toc_item(child, level + 1)
                    elif hasattr(item, 'title') and hasattr(item, 'href'):
                        # è¿™æ˜¯ä¸€ä¸ªç®€å•çš„é“¾æ¥é¡¹ç›®
                        toc_item = {
                            'level': level,
                            'title': item.title,
                            'href': item.href,
                            'type': 'link'
                        }
                        toc_info.append(toc_item)
                        print(f"{indent}ğŸ”— {item.title} -> {item.href}")
                    else:
                        print(f"{indent}âš ï¸ æœªçŸ¥çš„ç›®å½•é¡¹ç›®ç±»å‹: {type(item)}")
                except Exception as e:
                    print(f"{indent}âŒ å¤„ç†ç›®å½•é¡¹ç›®æ—¶å‡ºé”™: {e}")
            
            for item in self.book.toc:
                process_toc_item(item)
        else:
            print("\nâš ï¸ æœªæ‰¾åˆ°ç›®å½•ä¿¡æ¯")
        
        return toc_info
    
    def analyze_guide(self) -> List[Dict[str, Any]]:
        """åˆ†æå¯¼èˆªæŒ‡å—"""
        print("\n" + "="*60)
        print("ğŸ§­ å¯¼èˆªæŒ‡å—åˆ†æ")
        print("="*60)
        
        guide_info = []
        
        if self.book and self.book.guide:
            print(f"\nğŸ“ å¯¼èˆªæŒ‡å—åŒ…å« {len(self.book.guide)} ä¸ªé¡¹ç›®:")
            
            for item in self.book.guide:
                guide_item = {
                    'type': item.type,
                    'title': item.title,
                    'href': item.href
                }
                guide_info.append(guide_item)
                print(f"   ğŸ“Œ ç±»å‹: {item.type:15s} æ ‡é¢˜: {item.title:20s} é“¾æ¥: {item.href}")
        else:
            print("\nâš ï¸ æœªæ‰¾åˆ°å¯¼èˆªæŒ‡å—ä¿¡æ¯")
        
        return guide_info
    
    def analyze_all_items(self) -> List[Dict[str, Any]]:
        """åˆ†ææ‰€æœ‰é¡¹ç›®"""
        print("\n" + "="*60)
        print("ğŸ“¦ æ‰€æœ‰é¡¹ç›®åˆ†æ")
        print("="*60)
        
        all_items = []
        
        if self.book:
            items = list(self.book.get_items())
            print(f"\nğŸ“„ æ€»å…±æ‰¾åˆ° {len(items)} ä¸ªé¡¹ç›®:")
            
            for i, item in enumerate(items):
                try:
                    item_info = {
                        'index': i,
                        'id': item.get_id(),
                        'name': item.get_name(),
                        'type': item.get_type(),
                        'content_length': 0,
                        'content_preview': '',
                        'is_document': item.get_type() == ebooklib.ITEM_DOCUMENT
                    }
                    
                    # å¦‚æœæ˜¯æ–‡æ¡£ç±»å‹ï¼Œåˆ†æå†…å®¹
                    if item.get_type() == ebooklib.ITEM_DOCUMENT:
                        try:
                            content = item.get_content().decode('utf-8', errors='ignore')
                            soup = BeautifulSoup(content, 'html.parser')
                            text = soup.get_text().strip()
                            
                            item_info['content_length'] = len(text)
                            item_info['content_preview'] = text[:100] if text else ''
                            
                            # ä¿®å¤ï¼šä½¿ç”¨ç±»å‹åç§°æ˜ å°„
                            type_name = self.get_item_type_name(item.get_type())
                            print(f"   {i+1:2d}. ğŸ“„ {item.get_name():30s} [{type_name:15s}] {len(text):6d}å­—ç¬¦")
                            if text:
                                print(f"       é¢„è§ˆ: {text[:80]}...")
                        except Exception as e:
                            type_name = self.get_item_type_name(item.get_type())
                            print(f"   {i+1:2d}. ğŸ“„ {item.get_name():30s} [{type_name:15s}] è§£æé”™è¯¯: {e}")
                    else:
                        type_name = self.get_item_type_name(item.get_type())
                        print(f"   {i+1:2d}. ğŸ“ {item.get_name():30s} [{type_name:15s}]")
                    
                    all_items.append(item_info)
                    
                except Exception as e:
                    print(f"   {i+1:2d}. âŒ å¤„ç†é¡¹ç›®æ—¶å‡ºé”™: {e}")
                    continue
        
        return all_items
    
    def analyze_nav_document(self) -> Dict[str, Any]:
        """åˆ†æå¯¼èˆªæ–‡æ¡£ï¼ˆEPUB3ï¼‰"""
        print("\n" + "="*60)
        print("ğŸ—ºï¸ å¯¼èˆªæ–‡æ¡£åˆ†æï¼ˆEPUB3ï¼‰")
        print("="*60)
        
        nav_info = {'found': False, 'content': ''}
        
        if self.book:
            # æŸ¥æ‰¾å¯¼èˆªæ–‡æ¡£
            for item in self.book.get_items():
                try:
                    if item.get_type() == ebooklib.ITEM_NAVIGATION:
                        nav_info['found'] = True
                        try:
                            content = item.get_content().decode('utf-8', errors='ignore')
                            nav_info['content'] = content
                            
                            # ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨xmlè§£æå™¨
                            try:
                                soup = BeautifulSoup(content, 'xml')
                            except:
                                # å¦‚æœæ²¡æœ‰å®‰è£…lxmlï¼Œå›é€€åˆ°html.parser
                                import warnings
                                from bs4 import XMLParsedAsHTMLWarning
                                warnings.filterwarnings("ignore", category=XMLParsedAsHTMLWarning)
                                soup = BeautifulSoup(content, 'html.parser')
                            
                            nav_elements = soup.find_all('nav')
                            
                            print(f"\nğŸ“ æ‰¾åˆ°å¯¼èˆªæ–‡æ¡£: {item.get_name()}")
                            print(f"ğŸ“‹ åŒ…å« {len(nav_elements)} ä¸ªå¯¼èˆªå…ƒç´ :")
                            
                            for i, nav in enumerate(nav_elements):
                                nav_type = nav.get('epub:type', 'æœªçŸ¥ç±»å‹')
                                print(f"   {i+1}. å¯¼èˆªç±»å‹: {nav_type}")
                                
                                # æŸ¥æ‰¾åˆ—è¡¨é¡¹
                                ol_elements = nav.find_all('ol')
                                for ol in ol_elements:
                                    li_elements = ol.find_all('li')
                                    print(f"      åŒ…å« {len(li_elements)} ä¸ªåˆ—è¡¨é¡¹")
                                    
                                    for j, li in enumerate(li_elements[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                                        a_tag = li.find('a')
                                        if a_tag:
                                            title = a_tag.get_text().strip()
                                            href = a_tag.get('href', '')
                                            print(f"        {j+1}. {title} -> {href}")
                        except Exception as e:
                            print(f"âš ï¸ è§£æå¯¼èˆªæ–‡æ¡£æ—¶å‡ºé”™: {e}")
                        break
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†å¯¼èˆªé¡¹ç›®æ—¶å‡ºé”™: {e}")
                    continue
            
            if not nav_info['found']:
                print("\nâš ï¸ æœªæ‰¾åˆ°EPUB3å¯¼èˆªæ–‡æ¡£")
        
        return nav_info
    
    def generate_full_analysis(self, output_file: str = None) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´çš„ç»“æ„åˆ†ææŠ¥å‘Š"""
        if not self.load_epub():
            return None
        
        print(f"\nğŸ” å¼€å§‹åˆ†æEPUBç»“æ„: {os.path.basename(self.epub_path)}")
        
        analysis = {
            'file_path': self.epub_path,
            'file_name': os.path.basename(self.epub_path),
            'metadata': self.analyze_metadata(),
            'spine': self.analyze_spine(),
            'toc': self.analyze_toc(),
            'guide': self.analyze_guide(),
            'all_items': self.analyze_all_items(),
            'nav_document': self.analyze_nav_document()
        }
        
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        
        print("\n" + "="*60)
        print("âœ… ç»“æ„åˆ†æå®Œæˆ")
        print("="*60)
        
        return analysis

def main():
    """ä¸»å‡½æ•°"""
    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ŒåŸºäºå½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    epub_dir = os.path.join(script_dir, "epub-files")
    output_dir = os.path.join(script_dir, "analysis")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–epubæ–‡ä»¶åˆ—è¡¨
    epub_files = [f for f in os.listdir(epub_dir) if f.endswith('.epub')]
    
    print(f"ğŸš€ å¼€å§‹åˆ†æEPUBæ–‡ä»¶ç»“æ„...")
    print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {epub_dir}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“š æ‰¾åˆ° {len(epub_files)} ä¸ªEPUBæ–‡ä»¶\n")
    
    for epub_file in epub_files:
        epub_path = os.path.join(epub_dir, epub_file)
        output_file = os.path.join(output_dir, f"{os.path.splitext(epub_file)[0]}_structure.json")
        
        print(f"\n{'='*80}")
        print(f"ğŸ”„ åˆ†ææ–‡ä»¶: {epub_file}")
        print(f"{'='*80}")
        
        try:
            analyzer = EPUBStructureAnalyzer(epub_path)
            analysis = analyzer.generate_full_analysis(output_file)
            
            if analysis:
                print(f"âœ… {epub_file} åˆ†æå®Œæˆ")
            else:
                print(f"âŒ {epub_file} åˆ†æå¤±è´¥")
                
        except Exception as e:
            print(f"âŒ åˆ†æ {epub_file} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶åˆ†æå®Œæˆ!")
    print(f"ğŸ“ åˆ†ææŠ¥å‘Šä¿å­˜åœ¨: {output_dir}")

if __name__ == "__main__":
    main()